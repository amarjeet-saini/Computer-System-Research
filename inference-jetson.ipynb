{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing infernce on Jetson AGX by loading .trt engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import sys\n",
    "import progressbar\n",
    "import time\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import tensorrt as trt\n",
    "import os\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FP16 = True\n",
    "target_dtype = np.float16 if USE_FP16 else np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To create a test batch, we will once again repeat one open-source dog image from http://www.dog.ceo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='data_clean/n01440764-ILSVRC2012_val_00009191.JPEG'\n",
    "\n",
    "img = Image.open(url)\n",
    "\n",
    "if(img.mode != \"RGB\"):\n",
    "    img = img.convert(\"RGB\")\n",
    "\n",
    "img = np.array(img)\n",
    "img = resize(img, (224, 224))\n",
    "input_batch = np.array(np.repeat(np.expand_dims(np.array(img, dtype=np.float32), axis=0), BATCH_SIZE, axis=0), dtype=np.float32)\n",
    "\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step out of Python for a moment to convert the ONNX model to a TRT engine using trtexec\n",
    "# if USE_FP16:\n",
    "#     !trtexec --onnx=resnet50_pytorch.onnx --saveEngine=resnet_engine_pytorch.trt  --explicitBatch --inputIOFormats=fp16:chw --outputIOFormats=fp16:chw --fp16\n",
    "# else:\n",
    "#     !trtexec --onnx=resnet50_pytorch.onnx --saveEngine=resnet_engine_pytorch.trt  --explicitBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will save our model as 'resnet_engine.trt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 5000 images\n"
     ]
    }
   ],
   "source": [
    "# loading images from data_clean model\n",
    "images=[]\n",
    "names=[]\n",
    "\n",
    "for filename in os.listdir('data_clean'):\n",
    "    img = cv2.imread(os.path.join('data_clean',filename))\n",
    "    if img is not None:\n",
    "        images.append(img)\n",
    "        names.append(filename)\n",
    "\n",
    "print(\"loaded {} images\".format(len(images)))\n",
    "\n",
    "rows = open('synset.txt').read().strip().split(\"\\n\")\n",
    "classes = [r[r.find(\" \") + 1:] for r in rows]\n",
    "\n",
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 s, sys: 992 ms, total: 2.98 s\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "# load serialized model and convert to deserialize model\n",
    "\n",
    "%%time\n",
    "\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "f = open(\"mobile_gpu.trt\", \"rb\")\n",
    "runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING)) \n",
    "\n",
    "engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# need to set input and output precisions to FP16 to fully enable it\n",
    "output = np.empty([BATCH_SIZE, 1000], dtype = target_dtype) \n",
    "\n",
    "# allocate device memory\n",
    "d_input = cuda.mem_alloc(1 * input_batch.nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([               #[1]\n",
    "    transforms.Resize(256),                    #[2]\n",
    "    transforms.CenterCrop(224),                #[3]\n",
    "    transforms.ToTensor(),                     #[4]\n",
    "    transforms.Normalize(                      #[5]\n",
    "    mean=[0.485, 0.456, 0.406],                #[6]\n",
    "    std=[0.229, 0.224, 0.225]                  #[7]\n",
    "    )])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification took 93.223 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "bar = progressbar.ProgressBar(maxval=len(images), widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "\n",
    "\n",
    "for i in range(0,len(images)):\n",
    "    img = Image.open(\"data_clean/\"+names[i])\n",
    "    if(img.mode != \"RGB\"):\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    host_input = np.array(batch_t.numpy(), dtype=np.float16)\n",
    "    \n",
    "\n",
    "    cuda.memcpy_htod_async(d_input, host_input, stream)\n",
    "    # execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "    \n",
    "    indices = (-output[0]).argsort()[:5]\n",
    "    # append infernce output to data list\n",
    "    data.append((names[i], output[0][indices[0]],classes[indices[0]]))\n",
    "\n",
    "    bar.update(i+1)\n",
    "\n",
    "bar.finish()\n",
    "end = time.time()\n",
    "print(\"classification took {:.5} seconds\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store result in file\n",
    "import sys\n",
    "sys.stdout = open('mobilegpu_clean.txt','wt')\n",
    "for i in range(0,len(data)):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert pytorch model to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1,3,224,224)\n",
    "model = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "torch.onnx.export(model, dummy_input, \"mobilenet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "model = onnx.load(\"inceptionv3.onnx\")\n",
    "onnx.checker.check_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
